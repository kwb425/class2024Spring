{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwb425/class2024Spring/blob/main/class2024Spring_0405-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltUO0sYwyGfU"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di6xZ08xsgO7"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbHEyyNHntcZ"
      },
      "outputs": [],
      "source": [
        "text = 'Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. \\\n",
        "The ones who see things differently — they’re not fond of rules. \\\n",
        "You can quote them, disagree with them, glorify or vilify them, \\\n",
        "but the only thing you can’t do is ignore them because they change things. \\\n",
        "They push the human race forward, and while some may see them as the crazy ones, we see genius, \\\n",
        "because the ones who are crazy enough to think that they can change the world, are the ones who do.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45jV2UYs1GEC"
      },
      "outputs": [],
      "source": [
        "text.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFR-cRaahTPy"
      },
      "outputs": [],
      "source": [
        "' '.join(text.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq_lPZMHntcb"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "words = word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC1fe7nWF6wN"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\")\n",
        "words = retokenize.tokenize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc42Plwx56YS"
      },
      "source": [
        "### Normalization  \n",
        "Stemming: am → am, the going → the go, having → hav  \n",
        "Lemmatization: am → be, the going → the going, having → have"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsFfoAr259Fs"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkbgNiPd8BdL"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIIh5pYd8f74"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "[lemmatizer.lemmatize(w) for w in words]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPgIzrjm8_1N"
      },
      "source": [
        "### Stopword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdM2FaN8ntcc"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "print(words)\n",
        "words = [w for w in words if not w in stopwords.words('english')]\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmwXTL0UA5aw"
      },
      "source": [
        "### Collocation, Concordance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fll4ygxNA3OJ"
      },
      "outputs": [],
      "source": [
        "nltk.download('gutenberg')\n",
        "text = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
        "words = retokenize.tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqVXlhIrAtmf"
      },
      "outputs": [],
      "source": [
        "nltk.Text(words).collocations()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq0wiutwA_au"
      },
      "outputs": [],
      "source": [
        "nltk.Text(words).concordance('Emma', 79, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIAIhXvP_BjU"
      },
      "outputs": [],
      "source": [
        "nltk.Text(words).dispersion_plot([\"Emma\", \"Knightley\", \"Frank\", \"Jane\", \"Harriet\", \"Robert\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWYZOFxq_ex2"
      },
      "outputs": [],
      "source": [
        "nltk.Text(words).similar(\"Emma\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZihiVSBK_vy7"
      },
      "outputs": [],
      "source": [
        "nltk.Text(words).common_contexts([\"Emma\", \"she\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8TrCE14vGcT"
      },
      "source": [
        "### Frequency distribution, Frequency plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdY3m6zSBHic"
      },
      "outputs": [],
      "source": [
        "fd = nltk.FreqDist(words).most_common(20)\n",
        "fd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tpZThNV-ftv"
      },
      "outputs": [],
      "source": [
        "nltk.Text(words).plot(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSOSzIovvKvE"
      },
      "source": [
        "### Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIcAOAvqntce"
      },
      "outputs": [],
      "source": [
        "nltk.download('words')\n",
        "nltk.corpus.words.words('en')[-20:-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjAy_Ju7ntce"
      },
      "outputs": [],
      "source": [
        "len(nltk.corpus.words.words('en'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrVGVc0X9j7r"
      },
      "source": [
        "### Regular expression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQKgoQFI_cG-"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypDm1tB7fsRf"
      },
      "outputs": [],
      "source": [
        "out = re.search('w', 'Words, words, words.')\n",
        "print(out)\n",
        "print(out[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UFxn0pDG6AI"
      },
      "outputs": [],
      "source": [
        "out = re.search('V', 'Words, words, words.')\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8x2juS2G-VI"
      },
      "outputs": [],
      "source": [
        "out = re.findall('w', 'Words, words, words.')\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7St_KyzHFpY"
      },
      "outputs": [],
      "source": [
        "out = re.findall('V', 'Words, words, words.')\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0yzHS5zHLV8"
      },
      "outputs": [],
      "source": [
        "out = re.sub('w', 'V', 'Words, words, words.')\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U2pS-NL9p38"
      },
      "outputs": [],
      "source": [
        "'''       Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\n",
        "\n",
        ".\t        Wildcard, matches any character\n",
        "^abc\t    Matches some pattern abc at the start of a string\n",
        "abc$\t    Matches some pattern abc at the end of a string\n",
        "[abc]\t    Matches one of a set of characters\n",
        "[^abc]    Matches anything but a set of characters\n",
        "[A-Z0-9]\tMatches one of a range of characters\n",
        "ed|ing|s\tMatches one of the specified strings (disjunction)\n",
        "*\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\n",
        "+\t        One or more of previous item, e.g. a+, [a-z]+\n",
        "?\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\n",
        "{n}\t      Exactly n repeats where n is a non-negative integer\n",
        "{n,}\t    At least n repeats\n",
        "{,n}\t    No more than n repeats\n",
        "{m,n}\t    At least m and no more than n repeats\n",
        "a(b|c)+\t  Parentheses that indicate the scope of the operators\n",
        "(...)     Matches whatever regular expression is inside the parentheses\n",
        "\\d\n",
        "Matches any decimal digit; this is equivalent to the class [0-9].\n",
        "\\D\n",
        "Matches any non-digit character; this is equivalent to the class [^0-9].\n",
        "\\s\n",
        "Matches any whitespace character; this is equivalent to the class [ \\t\\n\\r\\f\\v].\n",
        "\\S\n",
        "Matches any non-whitespace character; this is equivalent to the class [^ \\t\\n\\r\\f\\v].\n",
        "\\w\n",
        "Matches any alphanumeric character; this is equivalent to the class [a-zA-Z0-9_].\n",
        "\\W\n",
        "Matches any non-alphanumeric character; this is equivalent to the class [^a-zA-Z0-9_].\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp3_Dm9Q_tNQ"
      },
      "outputs": [],
      "source": [
        "engdict = nltk.corpus.words.words('en')\n",
        "\n",
        "result = [w for w in engdict if re.search('ed$', w)]\n",
        "# result = [w for w in engdict if re.search('^..j..t..$', w)]\n",
        "# result = [w for w in engdict if re.search('^[ghi][mno][jlk][def]$', w)]\n",
        "# result = [w for w in engdict if re.search('^[ah]+$', w)][:10]\n",
        "print(result[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1a5mQYj4hwn"
      },
      "outputs": [],
      "source": [
        "nltk.download('treebank')\n",
        "wsj = nltk.corpus.treebank.words()\n",
        "\n",
        "result = [w for w in wsj if re.search('(ed|ing)$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]\n",
        "# result = [w for w in wsj if re.search('^[A-Z]+\\$$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]{4}$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]\n",
        "# result = [w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]\n",
        "\n",
        "result = sorted(set(result))\n",
        "print(result[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uakyZRspOTzg"
      },
      "outputs": [],
      "source": [
        "''' lookaround\n",
        "\n",
        "x(?=y) Matches \"x\" only if \"x\" is followed by \"y\"\n",
        "x(?!y) Matches \"x\" only if \"x\" is not followed by \"y\"\n",
        "(?<=y)x Matches \"x\" only if \"x\" is preceded by \"y\"\n",
        "(?<!y)x Matches \"x\" only if \"x\" is not preceded by \"y\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP0GUMkiPxbB"
      },
      "outputs": [],
      "source": [
        "re.sub('.afd', 'x', 'ddafadsfsafdsaf')\n",
        "# re.sub('.(?=afd)', 'xx', 'ddafadsfsafdsaf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0vHmkFmOgZA"
      },
      "outputs": [],
      "source": [
        "# capturing\n",
        "re.findall('\\d{4}-(\\d\\d)-(\\d\\d)', '2028-07-28')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyIIqwosCRZa"
      },
      "source": [
        "### Extract information (pos tag, named entity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VBiObftCVwH"
      },
      "outputs": [],
      "source": [
        "sent = \"I am Jhon from America and would like to go to Starbuck\"\n",
        "words = nltk.word_tokenize(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2HuyzFWCe3U"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "POS tag list:\n",
        "\n",
        "CC\tcoordinating conjunction\n",
        "CD\tcardinal digit\n",
        "DT\tdeterminer\n",
        "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
        "FW\tforeign word\n",
        "IN\tpreposition/subordinating conjunction\n",
        "JJ\tadjective\t'big'\n",
        "JJR\tadjective, comparative\t'bigger'\n",
        "JJS\tadjective, superlative\t'biggest'\n",
        "LS\tlist marker\t1)\n",
        "MD\tmodal\tcould, will\n",
        "NN\tnoun, singular 'desk'\n",
        "NNS\tnoun plural\t'desks'\n",
        "NNP\tproper noun, singular\t'Harrison'\n",
        "NNPS\tproper noun, plural\t'Americans'\n",
        "PDT\tpredeterminer\t'all the kids'\n",
        "POS\tpossessive ending\tparent's\n",
        "PRP\tpersonal pronoun\tI, he, she\n",
        "PRP$\tpossessive pronoun\tmy, his, hers\n",
        "RB\tadverb\tvery, silently,\n",
        "RBR\tadverb, comparative\tbetter\n",
        "RBS\tadverb, superlative\tbest\n",
        "RP\tparticle\tgive up\n",
        "TO\tto\tgo 'to' the store.\n",
        "UH\tinterjection\terrrrrrrrm\n",
        "VB\tverb, base form\ttake\n",
        "VBD\tverb, past tense\ttook\n",
        "VBG\tverb, gerund/present participle\ttaking\n",
        "VBN\tverb, past participle\ttaken\n",
        "VBP\tverb, sing. present, non-3d\ttake\n",
        "VBZ\tverb, 3rd person sing. present\ttakes\n",
        "WDT\twh-determiner\twhich\n",
        "WP\twh-pronoun\twho, what\n",
        "WP$\tpossessive wh-pronoun\twhose\n",
        "WRB\twh-abverb\twhere, when\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwKdu36WCewv"
      },
      "outputs": [],
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "pos = nltk.pos_tag(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnjGT1HpClE0"
      },
      "outputs": [],
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "NE = nltk.ne_chunk(pos)\n",
        "# common Entity types: ORGANIZATION, PERSON, LOCATION, DATE, TIME, MONEY, and GPE (geo-political entity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt9DEIZ4lXQF"
      },
      "source": [
        "### Wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jypxOnw9hoyZ"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text = nltk.corpus.gutenberg.raw('bible-kjv.txt')\n",
        "\n",
        "wc = WordCloud().generate(text)\n",
        "plt.imshow(wc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6xv5ClAl5xk"
      },
      "outputs": [],
      "source": [
        "stopwords = set(STOPWORDS)\n",
        "stopwords.add('unto')\n",
        "wc = WordCloud(stopwords = stopwords).generate(text)\n",
        "plt.imshow(wc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "nlp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
